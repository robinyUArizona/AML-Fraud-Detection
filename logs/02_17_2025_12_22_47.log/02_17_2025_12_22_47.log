[ 2025-02-17 12:22:48,733] 23 root - INFO - Entered the 'data ingestion' method or component
[ 2025-02-17 12:22:48,733] 29 root - INFO - CSV File Path:, /Users/robins/Desktop/Robins World/Data Science - Machine Learning Prep/01 - MLOps/AML-Fraud-Detection/notebook/data/HI-Small_Trans.csv
[ 2025-02-17 12:22:48,733] 33 root - INFO - File found: /Users/robins/Desktop/Robins World/Data Science - Machine Learning Prep/01 - MLOps/AML-Fraud-Detection/notebook/data/HI-Small_Trans.csv
[ 2025-02-17 12:22:51,776] 40 root - INFO - Read the dataset as DataFrame
[ 2025-02-17 12:22:51,859] 46 root - INFO - Train Test split initiated
[ 2025-02-17 12:22:51,953] 50 root - INFO - Ingestion of the data completed
[ 2025-02-17 12:22:52,031] 68 root - INFO - 
Entered the 'data transformation' method or component
[ 2025-02-17 12:22:52,064] 72 root - INFO - Reading train and test data completed
[ 2025-02-17 12:22:52,064] 76 root - INFO - Train and Test dataframe columns name renamed
[ 2025-02-17 12:22:52,066] 78 root - INFO - Train Dataframe Head : 
          timestamp  from_bank    account  to_bank  account_1  amount_received receiving_currency   amount_paid payment_currency payment_format  is_laundering
0  2022/09/02 11:26     353132  814282F31   255063  814282BC1          0.02664            Bitcoin       0.02664          Bitcoin        Bitcoin              0
1  2022/09/02 04:29      29003  80B58DFD0   123390  80EC2ACA0      91604.31000          US Dollar   91604.31000        US Dollar            ACH              0
2  2022/09/10 01:30     143430  810A32FA0   244192  811917200       2145.51000             Shekel    2145.51000           Shekel         Cheque              0
3  2022/09/07 21:25      16678  806484950    17554  806AAFE90     108457.21000              Ruble  108457.21000            Ruble         Cheque              0
4  2022/09/02 06:22        210  809181590    24779  80924A880       7577.02000    Canadian Dollar    7577.02000  Canadian Dollar    Credit Card              0
[ 2025-02-17 12:22:52,067] 79 root - INFO - Test Dataframe Head : 
          timestamp  from_bank    account  to_bank  account_1  amount_received receiving_currency  amount_paid payment_currency payment_format  is_laundering
0  2022/09/09 19:26      33727  80C66DAE0    33727  80C66DAE0         16515.55          US Dollar    349189.96     Mexican Peso            ACH              0
1  2022/09/08 18:24      28694  8036FA390   122151  80BDB1470           169.14          US Dollar       169.14        US Dollar           Cash              0
2  2022/09/05 16:06         70  1004286A8    13057  80189B650         19878.41               Euro     19878.41             Euro    Credit Card              0
3  2022/09/06 15:53          9  8060A15C0        9  8060B3140          8390.38              Ruble      8390.38            Ruble           Cash              0
4  2022/09/09 19:12       1853  801449850    17729  808FBDE10            98.92          US Dollar        98.92        US Dollar         Cheque              0
[ 2025-02-17 12:22:52,085] 111 root - INFO - Columns name of numerical features: ['amount_received']
[ 2025-02-17 12:22:52,087] 113 root - INFO - Columns name of categorical features: ['account', 'account_1', 'payment_format', 'day']
[ 2025-02-17 12:22:52,087] 115 root - INFO - Obtaining proprocessing object
[ 2025-02-17 12:22:52,087] 59 root - INFO - Preprocessed both numerical and categorical columns
[ 2025-02-17 12:22:52,087] 118 root - INFO - Applying preprocessing object on training and testing datasets.
[ 2025-02-17 12:22:52,281] 132 root - INFO - Saved data preprocessing object
[ 2025-02-17 12:22:52,285] 27 root - INFO - Get Independent features and Dependent feature from Train and Test datasets
[ 2025-02-17 12:22:52,285] 35 root - INFO - Imbalance dataset - upsampling the train data
[ 2025-02-17 12:22:52,287] 46 root - INFO - Before SMOTE: Counter({np.float64(0.0): 39959, np.float64(1.0): 41})
[ 2025-02-17 12:22:52,328] 48 root - INFO - After SMOTE: Counter({np.float64(0.0): 39959, np.float64(1.0): 39959})
[ 2025-02-17 12:22:52,328] 49 root - INFO - Upsampling the minority class data completed
[ 2025-02-17 12:22:52,329] 81 root - INFO - Grid Search started for RandomForestClassifier()
[ 2025-02-17 12:23:00,882] 85 root - INFO - Grid Search completed for RandomForestClassifier()
[ 2025-02-17 12:23:00,882] 88 root - INFO - Best parameters: {'n_estimators': 50} for RandomForestClassifier()
[ 2025-02-17 12:23:02,565] 98 root - INFO - Obtaining evaluation metrics for RandomForestClassifier(n_estimators=50) by using best hyperparameters
[ 2025-02-17 12:23:02,586] 81 root - INFO - Grid Search started for AdaBoostClassifier()
[ 2025-02-17 12:23:19,354] 85 root - INFO - Grid Search completed for AdaBoostClassifier()
[ 2025-02-17 12:23:19,354] 88 root - INFO - Best parameters: {'learning_rate': 1.0, 'n_estimators': 200} for AdaBoostClassifier()
[ 2025-02-17 12:23:23,849] 98 root - INFO - Obtaining evaluation metrics for AdaBoostClassifier(n_estimators=200) by using best hyperparameters
[ 2025-02-17 12:23:23,871] 81 root - INFO - Grid Search started for XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)
[ 2025-02-17 12:23:25,820] 85 root - INFO - Grid Search completed for XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)
[ 2025-02-17 12:23:25,820] 88 root - INFO - Best parameters: {'learning_rate': 0.1, 'n_estimators': 200} for XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)
[ 2025-02-17 12:23:26,169] 98 root - INFO - Obtaining evaluation metrics for XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=200, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...) by using best hyperparameters
[ 2025-02-17 12:23:26,181] 119 root - INFO - 
 Metrics calculation on Train Data: 
{'Random Forest': [{'Precision': 0.9998999024050954, 'Recall': 0.9998998973948297, 'F1 score': 0.9998998973950806, 'Confusion Matrix': array([[39953,     2],
       [    6, 39957]])}], 'AdaBoost': [{'Precision': 0.9684769752932288, 'Recall': 0.9674040891914212, 'F1 score': 0.9674215844264595, 'Confusion Matrix': array([[37731,   377],
       [ 2228, 39582]])}], 'XGBoost': [{'Precision': 0.9906379325978477, 'Recall': 0.9905027653344678, 'F1 score': 0.9905034072354595, 'Confusion Matrix': array([[39251,    51],
       [  708, 39908]])}]}
[ 2025-02-17 12:23:26,181] 121 root - INFO - 
 Metrics calculation on Test Data: 
{'Random Forest': [{'Precision': 0.9616342306536959, 'Recall': 0.9787, 'F1 score': 0.9694396431405047, 'Confusion Matrix': array([[9786,   12],
       [ 201,    1]])}], 'AdaBoost': [{'Precision': 0.9218786098851584, 'Recall': 0.9371, 'F1 score': 0.9079230021968008, 'Confusion Matrix': array([[9362,    4],
       [ 625,    9]])}], 'XGBoost': [{'Precision': 0.9574942194083078, 'Recall': 0.9765, 'F1 score': 0.9661644786073622, 'Confusion Matrix': array([[9764,   12],
       [ 223,    1]])}]}
[ 2025-02-17 12:23:26,181] 89 root - INFO - The models and their corresponding Recall score: 
{'Random Forest': 0.9787, 'AdaBoost': 0.9371, 'XGBoost': 0.9765}
[ 2025-02-17 12:23:26,181] 93 root - INFO - Best Model: Random Forest with Recall score: 0.9787
[ 2025-02-17 12:23:26,207] 108 root - INFO - Model Training completed
[ 2025-02-17 12:23:26,207] 109 root - INFO - Final Recall score for the RandomForestClassifier(n_estimators=50): 0.9787
